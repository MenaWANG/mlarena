{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Tips & Best Practices\n",
    "\n",
    "This notebook discusses ML best practices and how to easily implement them using `mlarena`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "# Third party imports\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "from mlarena import PreProcessor, ML_PIPELINE\n",
    "\n",
    "# Configure parallel processing\n",
    "# Only needed when running locally (not required on distributed platforms like Databricks)\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "n_jobs = max(1, n_cores // 2)  # Use half of available cores to avoid overloading\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = str(n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart One-Hot Encoding üé≠\n",
    "\n",
    "### The Tale of Two Models\n",
    "\n",
    "Linear models and tree-based models have different preferences for dropping categories in one-hot encoding:\n",
    "\n",
    "* **Linear Models** prefers having one category dropped:\n",
    "  - Avoid perfect multicollinearity \n",
    "    > When all dummy variables are included, they sum to 1, creating perfect multicollinearity which harms the performance of linear models.\n",
    "  - Makes coefficients more interpretable\n",
    "    >Dropping one category establishes it as the reference point, so each coefficient shows the effect compared to that baseline category.\n",
    "  - Improves numerical stability\n",
    "    >Removing redundant information improves matrix conditioning, leading to more stable and reliable parameter estimates.\n",
    "  \n",
    "* **Tree Models** üå≤ may prefer having all categories:\n",
    "  - Can directly split on any category \n",
    "    > Tree models evaluate one feature at a time. If a category is dropped, it can only be inferred when all other dummy features are zero ‚Äî a pattern that tree models can't easily learn. Keeping all categories ensures the model can split explicitly on each one.\n",
    "  - Clearer feature importance interpretation:  \n",
    "    >Each category has its own dummy feature, making it possible to directly assess how important each category is to the model ‚Äî no hidden or implicit categories.\n",
    "\n",
    "However, for binary categories (with just two values), keeping only one column is generally more efficient regardless of model type. One column perfectly represents the information, while two columns would be redundant. ‚öñÔ∏è\n",
    "\n",
    "It's worth noting that while these preferences exist, the choice between dropping categories or keeping them all is typically not a critical decision that dramatically impacts model performance. These are technical considerations that may offer incremental improvements, particularly for model interpretability and stability rather than substantial performance gains.\n",
    "\n",
    "### An Elegant Solution ü•Ç\n",
    "\n",
    "Sklearn's OneHotEncoder provides options to handle this smoothly through its `drop` parameter:\n",
    "\n",
    "* `drop=\"first\"`: \n",
    "  - Drops first category for all features\n",
    "  - Ideal for linear models\n",
    "  - More compact representation\n",
    "\n",
    "* `drop=\"if_binary\"`:\n",
    "  - Only drops one category for binary features\n",
    "  - Keeps all categories for multi-value features\n",
    "  - Can be effective for tree-based models\n",
    "\n",
    "This way you can optimize the encoding strategy based on your model type while maintaining efficient encoding for binary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
    "X = titanic.data\n",
    "y = titanic.target.astype(int)\n",
    "X = X.drop([\"boat\", \"body\", \"home.dest\", \"ticket\", \"cabin\", \"name\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Demo of the `drop` Parameter\n",
    "\n",
    "Below you can see a demo comparing two settings of the `drop` parameter with a tree-based algorithm (`lightGBM`):\n",
    "* Simple configuration with `mlarena` by passing the `drop` parameter to `PreProcessor` constructor\n",
    "* `drop=\"first\"`: Drops the first category for all categorical features\n",
    "* `drop=\"if_binary\"`: Only drops one category for binary features, keeps all categories for multi-value features\n",
    "\n",
    "The results show:\n",
    "* Some tree-based models may perform slightly better with `drop=\"if_binary\"` due to the reasons discussed above\n",
    "* The performance difference is generally small, so it's worth testing both approaches for your specific use case\n",
    "* Binary features like 'sex' have one category dropped in both cases (as seen in the output)\n",
    "* Multi-value features like 'embarked' retain all categories with `drop=\"if_binary\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define, fit and evaluate when drop for all categorical featuers in one-hot encoding\n",
    "mlpipeline_drop = ML_PIPELINE(\n",
    "    model=lgb.LGBMClassifier(verbose=-1), preprocessor=PreProcessor(drop=\"first\")\n",
    ")\n",
    "mlpipeline_drop.fit(X_train, y_train)\n",
    "results_drop = mlpipeline_drop.evaluate(\n",
    "    X_test, y_test, verbose=False, visualize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define, fit and evaluate when only drop for binary categories in one-hot encoding\n",
    "mlpipeline_drop_binary_only = ML_PIPELINE(\n",
    "    model=lgb.LGBMClassifier(verbose=-1), preprocessor=PreProcessor(drop=\"if_binary\")\n",
    ")\n",
    "mlpipeline_drop_binary_only.fit(X_train, y_train)\n",
    "results_drop_binary_only = mlpipeline_drop_binary_only.evaluate(\n",
    "    X_test, y_test, verbose=False, visualize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC when drop='first': 0.87\n",
      "AUC when drop='if_binary': 0.88\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(f\"AUC when drop='first': {results_drop['auc']:.2f}\")\n",
    "print(f\"AUC when drop='if_binary': {results_drop_binary_only['auc']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When drop is set to be 'if_binary' (vs 'first'), the additional column in transformed feature set is ['embarked_C']\n",
      "The binary sex feature will still be left with only one column.\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed_drop = mlpipeline_drop.preprocessor.transform(X_test)\n",
    "X_test_transformed_drop_binary_only = mlpipeline_drop_binary_only.preprocessor.transform(X_test)\n",
    "print(\n",
    "    f\"When drop is set to be 'if_binary' (vs 'first'), the additional column in transformed feature set is {[item for item in X_test_transformed_drop_binary_only.columns.tolist() if item not in X_test_transformed_drop.columns.tolist()]}\"\n",
    "    f\"\\nThe binary sex feature will still be left with only one column.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.451334</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.510089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.721918</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>0.676472</td>\n",
       "      <td>-0.343626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.495198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.492219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.498015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pclass       age     sibsp     parch      fare  sex_male  embarked_C  \\\n",
       "1148  0.840359  0.451334 -0.495964 -0.442432 -0.510089       1.0         0.0   \n",
       "1049  0.840359 -0.721918  0.456833  0.676472 -0.343626       1.0         1.0   \n",
       "982   0.840359 -0.096184 -0.495964 -0.442432 -0.495198       1.0         0.0   \n",
       "808   0.840359 -0.096184 -0.495964 -0.442432 -0.492219       1.0         0.0   \n",
       "1195  0.840359 -0.096184 -0.495964 -0.442432 -0.498015       1.0         0.0   \n",
       "\n",
       "      embarked_Q  embarked_S  \n",
       "1148         0.0         1.0  \n",
       "1049         0.0         0.0  \n",
       "982          0.0         1.0  \n",
       "808          0.0         1.0  \n",
       "1195         1.0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As expected, one column was dropped for the sex feature when drop is set to be \"if_binary\"\n",
    "X_test_transformed_drop_binary_only.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
