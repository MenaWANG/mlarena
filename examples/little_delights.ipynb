{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Devil is in the Details: MLArena's Little Delights 🎯✨\n",
    "\n",
    "Machine learning is full of those small but meaningful moments - from to presenting SHAP plots with actual values (rather than scaled ones) to stakeholders, to handling cryptic feature names that breaks the code, and to optimizing one-hot encoding strategy for different model types. These little details can make an ML practitioner's life so much smoother! That's why MLArena comes with thoughtful touches that show we've been in your shoes. 👣\n",
    "\n",
    "Think of this as a collection of ML quality-of-life improvements - like having a cup holder in exactly the right spot, or finding out your new jacket has inside pockets. Small things that make you smile and wonder why they aren't everywhere. Let's explore these delightful details that make MLArena not just powerful, but pleasantly surprising! 🎁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tale of Two Models: Smart One-Hot Encoding 🎭\n",
    "\n",
    "### The One-Hot Encoding Dilemma\n",
    "\n",
    "Linear models and tree-based models have different preferences when it comes to one-hot encoding:\n",
    "\n",
    "* **Linear Models** love having one category dropped (`drop=\"first\"`):\n",
    "  - Eliminates perfect multicollinearity\n",
    "  - Makes coefficients more interpretable (each coefficient represents difference from reference category)\n",
    "  - Improves numerical stability\n",
    "  \n",
    "* **Tree Models** may prefer having all categories (`drop=None`):\n",
    "  - Can directly split on any category:\n",
    "    > Tree models evaluate one feature at a time. If a category is dropped, it can only be inferred when all other dummy features are zero — a pattern that tree models can't easily learn. Keeping all categories ensures the model can split explicitly on each one.\n",
    "  - Better handling of feature interactions:\n",
    "    >  When all categories are present, tree models can more easily capture interactions between specific categories and other features, leading to more expressive and accurate trees.\n",
    "  - Clearer feature importance interpretation:  \n",
    "    >Each category has its own dummy feature, making it possible to directly assess how important each category is to the model — no hidden or implicit categories.\n",
    "\n",
    "But here is the twist: for binary categoreis with just two values, dropping one category is *always* better regardless of model type, because one column perfectly represent the split -- haveing two coumns adds no value while increasing dimensionality and render the results less interpretable (imaging reading feature importance of both gender_male and gender_female in shap plot)\n",
    "\n",
    "### MLArena's Easy Solution 🥂\n",
    "\n",
    "It is a bit of coding to do to implement the above process for linear and tree models respectively, but this is handled automatically in `mlarena`. Specifically, a `drop_first` parameter is included in `PreProcessor`:\n",
    "\n",
    "* when `drop_first` = True\n",
    "    * set drop = fist for all one-hot encoded features, \n",
    "    * Ideal for linear models\n",
    "\n",
    "* when `drop_first` = False\n",
    "    * set drop = fist only for binary one-hot encoded features, \n",
    "    * May work better for some tree-based models\n",
    "\n",
    "This way:\n",
    "- Binary features stay efficient (always drop one category)\n",
    "- Multi-value features can be optimized for your particular model depending on its type (linear or tree-based)\n",
    "- You get experiment with and optimize encoding with zero hazzle  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "# Third party imports\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.datasets import (\n",
    "    fetch_openml\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier\n",
    ") \n",
    "  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mlarena import PreProcessor, ML_PIPELINE\n",
    "\n",
    "# Configure parallel processing\n",
    "# Only needed when running locally (not required on distributed platforms like Databricks)\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "n_jobs = max(1, n_cores // 2)  # Use half of available cores to avoid overloading\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = str(n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "titanic = fetch_openml('titanic', version=1, as_frame=True)\n",
    "X = titanic.data\n",
    "y = titanic.target.astype(int)  \n",
    "X = X.drop(['boat', 'body', 'home.dest', 'ticket', 'cabin', 'name'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with the `drop_first` Parameter\n",
    "\n",
    "Below you can see demo of the drop_first parameter implemented on both lightgbm and RandomForest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Report\n",
      "==================================================\n",
      "\n",
      "Evaluation Parameters:\n",
      "Threshold: 0.500\n",
      "Beta:      1.000\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.817\n",
      "F1:        0.782\n",
      "Precision: 0.843\n",
      "Recall:    0.729\n",
      "Pos Rate:  0.389\n",
      "\n",
      "AUC (threshold independent):\n",
      "AUC:   0.872\n"
     ]
    }
   ],
   "source": [
    "# define pipeline\n",
    "mlpipeline_drop = ML_PIPELINE(\n",
    "    model = lgb.LGBMClassifier(verbose=-1),\n",
    "    preprocessor = PreProcessor(drop_first = True)\n",
    "    )\n",
    "# fit pipeline\n",
    "mlpipeline_drop.fit(X_train,y_train)\n",
    "# evaluate pipeline with metrics and visualization\n",
    "results = mlpipeline_drop.evaluate(X_test,y_test, verbose=True, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.451334</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.510089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.721918</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>0.676472</td>\n",
       "      <td>-0.343626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.495198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.492219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.498015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pclass       age     sibsp     parch      fare  sex_male  embarked_Q  \\\n",
       "1148  0.840359  0.451334 -0.495964 -0.442432 -0.510089       1.0         0.0   \n",
       "1049  0.840359 -0.721918  0.456833  0.676472 -0.343626       1.0         0.0   \n",
       "982   0.840359 -0.096184 -0.495964 -0.442432 -0.495198       1.0         0.0   \n",
       "808   0.840359 -0.096184 -0.495964 -0.442432 -0.492219       1.0         0.0   \n",
       "1195  0.840359 -0.096184 -0.495964 -0.442432 -0.498015       1.0         1.0   \n",
       "\n",
       "      embarked_S  \n",
       "1148         1.0  \n",
       "1049         0.0  \n",
       "982          1.0  \n",
       "808          1.0  \n",
       "1195         0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed_drop = mlpipeline_drop.preprocessor.transform(X_test)\n",
    "X_test_transformed_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Report\n",
      "==================================================\n",
      "\n",
      "Evaluation Parameters:\n",
      "Threshold: 0.500\n",
      "Beta:      1.000\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.805\n",
      "F1:        0.765\n",
      "Precision: 0.838\n",
      "Recall:    0.703\n",
      "Pos Rate:  0.378\n",
      "\n",
      "AUC (threshold independent):\n",
      "AUC:   0.876\n"
     ]
    }
   ],
   "source": [
    "# define pipeline\n",
    "mlpipeline_no_drop = ML_PIPELINE(\n",
    "    model = lgb.LGBMClassifier(verbose=-1),\n",
    "    preprocessor = PreProcessor(drop_first = False)\n",
    "    )\n",
    "# fit pipeline\n",
    "mlpipeline_no_drop.fit(X_train,y_train)\n",
    "# evaluate pipeline with metrics and visualization\n",
    "results = mlpipeline_no_drop.evaluate(X_test,y_test, verbose=True, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.451334</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.510089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.721918</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>0.676472</td>\n",
       "      <td>-0.343626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.495198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.492219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.498015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pclass       age     sibsp     parch      fare  sex_male  embarked_C  \\\n",
       "1148  0.840359  0.451334 -0.495964 -0.442432 -0.510089       1.0         0.0   \n",
       "1049  0.840359 -0.721918  0.456833  0.676472 -0.343626       1.0         1.0   \n",
       "982   0.840359 -0.096184 -0.495964 -0.442432 -0.495198       1.0         0.0   \n",
       "808   0.840359 -0.096184 -0.495964 -0.442432 -0.492219       1.0         0.0   \n",
       "1195  0.840359 -0.096184 -0.495964 -0.442432 -0.498015       1.0         0.0   \n",
       "\n",
       "      embarked_Q  embarked_S  \n",
       "1148         0.0         1.0  \n",
       "1049         0.0         0.0  \n",
       "982          0.0         1.0  \n",
       "808          0.0         1.0  \n",
       "1195         1.0         0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed_no_drop = mlpipeline_no_drop.preprocessor.transform(X_test)\n",
    "X_test_transformed_no_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Report\n",
      "==================================================\n",
      "\n",
      "Evaluation Parameters:\n",
      "Threshold: 0.500\n",
      "Beta:      1.000\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.798\n",
      "F1:        0.758\n",
      "Precision: 0.822\n",
      "Recall:    0.703\n",
      "Pos Rate:  0.385\n",
      "\n",
      "AUC (threshold independent):\n",
      "AUC:   0.855\n"
     ]
    }
   ],
   "source": [
    "mlpipeline_drop = ML_PIPELINE(\n",
    "    model = RandomForestClassifier(),\n",
    "    preprocessor = PreProcessor(drop_first = True)\n",
    "    )\n",
    "# fit pipeline\n",
    "mlpipeline_drop.fit(X_train,y_train)\n",
    "# evaluate pipeline with metrics and visualization\n",
    "results = mlpipeline_drop.evaluate(X_test,y_test, verbose=True, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Report\n",
      "==================================================\n",
      "\n",
      "Evaluation Parameters:\n",
      "Threshold: 0.500\n",
      "Beta:      1.000\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.802\n",
      "F1:        0.759\n",
      "Precision: 0.837\n",
      "Recall:    0.695\n",
      "Pos Rate:  0.374\n",
      "\n",
      "AUC (threshold independent):\n",
      "AUC:   0.861\n"
     ]
    }
   ],
   "source": [
    "mlpipeline_no_drop = ML_PIPELINE(\n",
    "    model = RandomForestClassifier(),\n",
    "    preprocessor = PreProcessor(drop_first = False)\n",
    "    )\n",
    "# fit pipeline\n",
    "mlpipeline_no_drop.fit(X_train,y_train)\n",
    "# evaluate pipeline with metrics and visualization\n",
    "results = mlpipeline_no_drop.evaluate(X_test,y_test, verbose=True, visualize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
