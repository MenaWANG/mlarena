{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Tips & Best Practices\n",
    "\n",
    "This notebook discusses common challenges and best practices in machine learning workflows. For each topic, we navigate through the pros and cons of different approaches and demonstrate how `mlarena` address these practical considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "# Third party imports\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "from mlarena import PreProcessor, MLPipeline\n",
    "\n",
    "# Configure parallel processing\n",
    "# Only needed when running locally (not required on distributed platforms like Databricks)\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "n_jobs = max(1, n_cores // 2)  # Use half of available cores to avoid overloading\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = str(n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Pandas `category` Dtype in MLflow\n",
    "\n",
    "### MLflow's Handling of `category` Dtype: The Challenges\n",
    "\n",
    "The `mlflow.pyfunc` model flavor does **not natively support** the `pandas.CategoricalDtype` when logging input signatures (pls see [discussions on the issue on github](https://github.com/mlflow/mlflow/issues/3849)). Instead, it interprets categorical columns as either `string` or `object`. This behavior can introduce schema mismatches at inference time, especially if the model was trained on `category` data but later receives inputs with `category` dtype via `loaded_model.predict()`.\n",
    "\n",
    "As a result:\n",
    "- Logging works only if categorical columns are cast to `object` or `string`.\n",
    "- Predictions using the PyFunc model (`loaded_model.predict()`) fail when inputs contain `category` dtype.\n",
    "- The raw model (`loaded_model.unwrap_python_model()`) continues to support `category` inputs, as it reflects the original training environment.\n",
    "\n",
    "### Comparison of Approaches for Handling Categorical Data in MLflow\n",
    "\n",
    "| Approach | Pros | Cons | Use Case | Flexibility |\n",
    "|----------|------|------|----------|-------------|\n",
    "| **Cast `category` to `object` during training and logging** | - Works with MLflow signature (avoids dtype issues)<br>- Simple to implement | - Loses memory efficiency of `category`<br>- Loses categorical ordering (levels, semantics) | Basic models, local dev, MLflow-compatible | Low (requires manual updates) |\n",
    "| **Use feature transformers to standardize input** | - Ensures consistency across training and inference<br>- Reusable and scalable (via custom transformer or pipeline)<br>- Avoids schema mismatches | - Loses benefits of `category` dtype (e.g., memory efficiency, speed)<br>- Requires initial setup | Production pipelines, model serving, MLflow deployments | High (easy to adapt and scale for various input schemas) |\n",
    "| **Cast only before logging and inference** | - Efficient training with `category` dtype<br>- Avoids schema issues at logging/predicting time | - Requires careful and consistent casting at inference<br>- Slightly more complex | Local development, batch scoring | Moderate (can be error-prone in production) |\n",
    "| **Use `unwrap_python_model().predict()`** | - Keeps the full fidelity of training dtype (uses `category` dtype)<br>- Fast and flexible | - Bypasses MLflow's signature validation (could lead to errors at deployment)<br>- Not compatible with model serving or REST APIs | Local development, batch scoring | Moderate (adjustment needed for REST serving),pls see **Current Approach** and **Future considerations** below |\n",
    "\n",
    "\n",
    "### Current Approach used in `mlarena`\n",
    "\n",
    "- the unwrapped model (`unwrap_python_model().predict()`) can handle prediction with category dtypes\n",
    "- add a `mlflow_input_prep` function to `PreProcessor` and apply before prediction, which will work for PyFunc-based serving or REST inference.\n",
    "\n",
    "#### Advantages:\n",
    "- Maintains the benefits of using `category` dtype during training (memory and performance).\n",
    "- Avoids schema validation errors during development and testing.\n",
    "- Keeps the codebase lightweight and close to native pandas and scikit-learn usage.\n",
    "\n",
    "#### Trade-offs:\n",
    "- Requires additional logic (i.e., the `mlflow_input_prep` function) to handle input transformation.\n",
    "- Users need to be awareness of MLflow's limitations and potential future adjustments.\n",
    "\n",
    "### Future considerations:\n",
    "- An alternative approach would be to create a specialized model wrapper that automatically converts inputs to category dtypes based on a predefined schema. This wrapper would:\n",
    "    - Maintain a record of which columns should be categorical\n",
    "    - Convert these columns to category dtype before model processing\n",
    "    - Handle this conversion transparently for both training and prediction\n",
    "    - Ensure consistent dtype handling regardless of how the model is deployed\n",
    "- While this would add another layer of abstraction on top of MLPipeline, it could provide a more seamless experience for users working heavily with categorical data. \n",
    "- As MLflow continues to evolve, we'll monitor for native improvements in categorical data support, which would potentially eliminate the need for these workarounds.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart One-Hot Encoding üé≠\n",
    "\n",
    "### The Tale of Two Models\n",
    "\n",
    "Linear models and tree-based models have different preferences for dropping categories in one-hot encoding:\n",
    "\n",
    "* **Linear Models** prefers having one category dropped:\n",
    "  - Avoid perfect multicollinearity \n",
    "    > When all dummy variables are included, they sum to 1, creating perfect multicollinearity which harms the performance of linear models.\n",
    "  - Makes coefficients more interpretable\n",
    "    >Dropping one category establishes it as the reference point, so each coefficient shows the effect compared to that baseline category.\n",
    "  - Improves numerical stability\n",
    "    >Removing redundant information improves matrix conditioning, leading to more stable and reliable parameter estimates.\n",
    "  \n",
    "* **Tree Models** üå≤ may prefer having all categories:\n",
    "  - Can directly split on any category \n",
    "    > Tree models evaluate one feature at a time. If a category is dropped, it can only be inferred when all other dummy features are zero ‚Äî a pattern that tree models can't easily learn. Keeping all categories ensures the model can split explicitly on each one.\n",
    "  - Clearer feature importance interpretation:  \n",
    "    >Each category has its own dummy feature, making it possible to directly assess how important each category is to the model ‚Äî no hidden or implicit categories.\n",
    "\n",
    "However, for binary categories (with just two values), keeping only one column is generally more efficient regardless of model type. One column perfectly represents the information, while two columns would be redundant. ‚öñÔ∏è\n",
    "\n",
    "It's worth noting that while these preferences exist, the choice between dropping categories or keeping them all is typically not a critical decision that dramatically impacts model performance. These are technical considerations that may offer incremental improvements, particularly for model interpretability and stability rather than substantial performance gains.\n",
    "\n",
    "### An Elegant Solution ü•Ç\n",
    "\n",
    "Sklearn's OneHotEncoder provides options to handle this smoothly through its `drop` parameter:\n",
    "\n",
    "* `drop=\"first\"`: \n",
    "  - Drops first category for all features\n",
    "  - Ideal for linear models\n",
    "  - More compact representation\n",
    "\n",
    "* `drop=\"if_binary\"`:\n",
    "  - Only drops one category for binary features\n",
    "  - Keeps all categories for multi-value features\n",
    "  - Can be effective for tree-based models\n",
    "\n",
    "This way you can optimize the encoding strategy based on your model type while maintaining efficient encoding for binary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
    "X = titanic.data\n",
    "y = titanic.target.astype(int)\n",
    "X = X.drop([\"boat\", \"body\", \"home.dest\", \"ticket\", \"cabin\", \"name\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Demo of the `drop` Parameter\n",
    "\n",
    "Below you can see a demo comparing two settings of the `drop` parameter with a tree-based algorithm (`lightGBM`):\n",
    "* Simple configuration with `mlarena` by passing the `drop` parameter to `PreProcessor` constructor\n",
    "* `drop=\"first\"`: Drops the first category for all categorical features\n",
    "* `drop=\"if_binary\"`: Only drops one category for binary features, keeps all categories for multi-value features\n",
    "\n",
    "The results show:\n",
    "* Some tree-based models may perform slightly better with `drop=\"if_binary\"` due to the reasons discussed above\n",
    "* The performance difference is generally small, so it's worth testing both approaches for your specific use case\n",
    "* Binary features like 'sex' have one category dropped in both cases (as seen in the output)\n",
    "* Multi-value features like 'embarked' retain all categories with `drop=\"if_binary\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define, fit and evaluate when drop for all categorical featuers in one-hot encoding\n",
    "mlpipeline_drop = MLPipeline(\n",
    "    model=lgb.LGBMClassifier(verbose=-1), preprocessor=PreProcessor(drop=\"first\")\n",
    ")\n",
    "mlpipeline_drop.fit(X_train, y_train)\n",
    "results_drop = mlpipeline_drop.evaluate(\n",
    "    X_test, y_test, verbose=False, visualize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define, fit and evaluate when only drop for binary categories in one-hot encoding\n",
    "mlpipeline_drop_binary_only = MLPipeline(\n",
    "    model=lgb.LGBMClassifier(verbose=-1), preprocessor=PreProcessor(drop=\"if_binary\")\n",
    ")\n",
    "mlpipeline_drop_binary_only.fit(X_train, y_train)\n",
    "results_drop_binary_only = mlpipeline_drop_binary_only.evaluate(\n",
    "    X_test, y_test, verbose=False, visualize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC when drop='first': 0.87\n",
      "AUC when drop='if_binary': 0.88\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(f\"AUC when drop='first': {results_drop['auc']:.2f}\")\n",
    "print(f\"AUC when drop='if_binary': {results_drop_binary_only['auc']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When drop is set to be 'if_binary' (vs 'first'), the additional column in transformed feature set is ['embarked_C']\n",
      "The binary sex feature will still be left with only one column.\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed_drop = mlpipeline_drop.preprocessor.transform(X_test)\n",
    "X_test_transformed_drop_binary_only = mlpipeline_drop_binary_only.preprocessor.transform(X_test)\n",
    "print(\n",
    "    f\"When drop is set to be 'if_binary' (vs 'first'), the additional column in transformed feature set is {[item for item in X_test_transformed_drop_binary_only.columns.tolist() if item not in X_test_transformed_drop.columns.tolist()]}\"\n",
    "    f\"\\nThe binary sex feature will still be left with only one column.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.451334</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.510089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.721918</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>0.676472</td>\n",
       "      <td>-0.343626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.495198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.492219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.840359</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>-0.495964</td>\n",
       "      <td>-0.442432</td>\n",
       "      <td>-0.498015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pclass       age     sibsp     parch      fare  sex_male  embarked_C  \\\n",
       "1148  0.840359  0.451334 -0.495964 -0.442432 -0.510089       1.0         0.0   \n",
       "1049  0.840359 -0.721918  0.456833  0.676472 -0.343626       1.0         1.0   \n",
       "982   0.840359 -0.096184 -0.495964 -0.442432 -0.495198       1.0         0.0   \n",
       "808   0.840359 -0.096184 -0.495964 -0.442432 -0.492219       1.0         0.0   \n",
       "1195  0.840359 -0.096184 -0.495964 -0.442432 -0.498015       1.0         0.0   \n",
       "\n",
       "      embarked_Q  embarked_S  \n",
       "1148         0.0         1.0  \n",
       "1049         0.0         0.0  \n",
       "982          0.0         1.0  \n",
       "808          0.0         1.0  \n",
       "1195         1.0         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As expected, one column was dropped for the sex feature when drop is set to be \"if_binary\"\n",
    "X_test_transformed_drop_binary_only.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
